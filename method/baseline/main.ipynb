{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Är det lämpligt att gå med i ett välrenommerat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vilka städer nämner president Zelenskyj som nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hur kan jag få en tjej att verkligen bli kär i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vilka är möjliga orsaker till illamående, hals...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vad hävdar Ryska försvarsdepartementet att de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  label\n",
       "0  Är det lämpligt att gå med i ett välrenommerat...      0\n",
       "1  Vilka städer nämner president Zelenskyj som nu...      1\n",
       "2  Hur kan jag få en tjej att verkligen bli kär i...      0\n",
       "3  Vilka är möjliga orsaker till illamående, hals...      0\n",
       "4  Vad hävdar Ryska försvarsdepartementet att de ...      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  (6800, 2)\n",
      "testing data:  (1200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into train and test\n",
    "training_data, test_data = sklearn.model_selection.train_test_split(data, test_size = 0.15, random_state = 1)\n",
    "print(\"training data: \", training_data.shape)\n",
    "print(\"testing data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.953\n",
      "Best parameters set:\n",
      "\tclassifier__alpha: 0.08\n",
      "\tclassifier__loss: 'perceptron'\n",
      "\tclassifier__penalty: 'l2'\n",
      "\tvectorizer: TfidfVectorizer(binary=True, ngram_range=(1, 2))\n",
      "\tvectorizer__binary: True\n",
      "\tvectorizer__ngram_range: (1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "600 fits failed out of a total of 3600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 892, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 151, in _more_validate_params\n",
      "    raise ValueError(\n",
      "ValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89176471 0.89897059 0.89191176 0.89735294 0.87382353 0.84323529\n",
      " 0.87       0.83132353 0.76441176 0.76441176 0.765      0.765\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.86176471 0.85617647\n",
      " 0.85779412 0.85308824 0.76676471 0.60691176 0.74779412 0.5875\n",
      " 0.88161765 0.88867647 0.88       0.88676471 0.89514706 0.87661765\n",
      " 0.89588235 0.86897059 0.73838235 0.73147059 0.71279412 0.71279412\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.85102941 0.84985294\n",
      " 0.85352941 0.85058824 0.67852941 0.50397059 0.64161765 0.50397059\n",
      " 0.92088235 0.92911765 0.92323529 0.93088235 0.91882353 0.91647059\n",
      " 0.91985294 0.92088235 0.84455882 0.84617647 0.8475     0.84485294\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.88441176 0.88602941\n",
      " 0.88705882 0.88970588 0.85264706 0.83441176 0.85132353 0.82808824\n",
      " 0.76441176 0.76838235 0.79941176 0.80676471 0.91882353 0.91647059\n",
      " 0.91985294 0.92088235 0.90970588 0.91132353 0.90823529 0.90852941\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.78647059 0.80676471\n",
      " 0.81       0.81132353 0.85264706 0.83441176 0.85132353 0.82808824\n",
      " 0.93647059 0.94014706 0.94720588 0.94514706 0.94897059 0.94970588\n",
      " 0.9475     0.95308824 0.56691176 0.61117647 0.53235294 0.56617647\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.72955882 0.73220588\n",
      " 0.72088235 0.72338235 0.59132353 0.50397059 0.52573529 0.50397059\n",
      " 0.88352941 0.88602941 0.88014706 0.88352941 0.85926471 0.81911765\n",
      " 0.85617647 0.80808824 0.73205882 0.73323529 0.69676471 0.69676471\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.84176471 0.84102941\n",
      " 0.84647059 0.83882353 0.66617647 0.50705882 0.64191176 0.50661765\n",
      " 0.87441176 0.88029412 0.87294118 0.88058824 0.88132353 0.84852941\n",
      " 0.87911765 0.83735294 0.55779412 0.55779412 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.82514706 0.82441176\n",
      " 0.82191176 0.82191176 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.91       0.91647059 0.91132353 0.91794118 0.91632353 0.90676471\n",
      " 0.91823529 0.90705882 0.81867647 0.81867647 0.80617647 0.80617647\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.86867647 0.86926471\n",
      " 0.86602941 0.86485294 0.83720588 0.78264706 0.83279412 0.77823529\n",
      " 0.81397059 0.79632353 0.89720588 0.87808824 0.91632353 0.90676471\n",
      " 0.91823529 0.90705882 0.89411765 0.89735294 0.88102941 0.88691176\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.79676471 0.78705882\n",
      " 0.85941176 0.84220588 0.83720588 0.78264706 0.83279412 0.77823529\n",
      " 0.93308824 0.92808824 0.93647059 0.92911765 0.94632353 0.94897059\n",
      " 0.95044118 0.95323529 0.49926471 0.49926471 0.49926471 0.49926471\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.67014706 0.68014706\n",
      " 0.70705882 0.715      0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.88       0.88205882 0.87705882 0.87838235 0.85132353 0.80588235\n",
      " 0.84661765 0.79441176 0.71117647 0.71117647 0.65279412 0.65882353\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.83735294 0.83\n",
      " 0.84264706 0.83514706 0.61941176 0.50397059 0.57838235 0.50397059\n",
      " 0.87132353 0.87661765 0.87058824 0.87720588 0.8725     0.83308824\n",
      " 0.86955882 0.82058824 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.82102941 0.82073529\n",
      " 0.82044118 0.81970588 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.90485294 0.9125     0.90573529 0.9125     0.91220588 0.90088235\n",
      " 0.91470588 0.90161765 0.79264706 0.78735294 0.78632353 0.78632353\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.86073529 0.86191176\n",
      " 0.85897059 0.85838235 0.82676471 0.72117647 0.82352941 0.68794118\n",
      " 0.82588235 0.82691176 0.90294118 0.90632353 0.91220588 0.90088235\n",
      " 0.91470588 0.90161765 0.87558824 0.88617647 0.86823529 0.87441176\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.80602941 0.80264706\n",
      " 0.86058824 0.855      0.82676471 0.72117647 0.82352941 0.68794118\n",
      " 0.91985294 0.91941176 0.91794118 0.92058824 0.94720588 0.94867647\n",
      " 0.95220588 0.95014706 0.50073529 0.49926471 0.4975     0.49926471\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.68632353 0.67\n",
      " 0.63882353 0.65970588 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.86279412 0.86647059 0.86058824 0.86514706 0.795      0.72985294\n",
      " 0.78485294 0.71514706 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.77588235 0.77558824\n",
      " 0.75764706 0.75823529 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.86397059 0.87       0.86191176 0.86867647 0.80691176 0.74382353\n",
      " 0.79720588 0.72867647 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.72382353 0.72382353\n",
      " 0.68705882 0.68705882 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.88264706 0.88882353 0.88147059 0.88676471 0.86647059 0.81323529\n",
      " 0.86397059 0.80397059 0.62647059 0.62647059 0.62647059 0.56294118\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.82926471 0.82955882\n",
      " 0.82514706 0.82529412 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.88882353 0.89647059 0.88441176 0.88911765 0.86647059 0.81323529\n",
      " 0.86397059 0.80397059 0.70397059 0.71573529 0.56235294 0.52867647\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.84132353 0.84220588\n",
      " 0.83352941 0.83397059 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.88926471 0.87676471 0.88632353 0.87352941 0.95117647 0.94691176\n",
      " 0.95073529 0.95073529 0.50220588 0.50220588 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.57558824 0.57044118\n",
      " 0.53823529 0.50220588 0.50397059 0.50397059 0.50397059 0.50397059\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.82705882 0.85352941 0.81514706 0.84161765 0.50279412 0.5025\n",
      " 0.50279412 0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.82808824 0.85470588 0.81617647 0.84411765 0.50279412 0.5025\n",
      " 0.50279412 0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.83573529 0.85867647 0.82852941 0.85426471 0.50308824 0.5025\n",
      " 0.50294118 0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.83573529 0.85867647 0.82852941 0.85426471 0.50308824 0.5025\n",
      " 0.50294118 0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.5025     0.5025     0.5025     0.5025     0.5025     0.5025\n",
      " 0.78779412 0.79029412 0.78573529 0.78955882 0.87044118 0.87235294\n",
      " 0.86882353 0.87117647 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.50397059 0.50397059\n",
      " 0.50397059 0.50397059 0.50397059 0.50397059 0.50397059 0.50397059]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('vectorizer', sklearn.feature_extraction.text.CountVectorizer()),\n",
    "    ('classifier', sklearn.linear_model.SGDClassifier(random_state=1, max_iter=3000))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer': [sklearn.feature_extraction.text.CountVectorizer(), sklearn.feature_extraction.text.TfidfVectorizer()],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'classifier__alpha': [0.05, 0.08, 0.1, 0.3, 0,5],\n",
    "    'classifier__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'classifier__loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "}\n",
    "\n",
    "grid_search = sklearn.model_selection.GridSearchCV(pipeline, parameters, cv = 5, n_jobs = -1, verbose = 1)\n",
    "grid_search.fit(training_data['question'], training_data['label'])\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       627\n",
      "           1       0.96      0.96      0.96       573\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.96      0.96      0.96      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineBestParams = sklearn.pipeline.Pipeline([\n",
    "    ('vectorizer', sklearn.feature_extraction.text.TfidfVectorizer(binary=True, ngram_range=(1, 2))),\n",
    "    ('classifier', sklearn.linear_model.SGDClassifier(random_state=1, max_iter=3000, alpha=0.08, loss = \"perceptron\", penalty = \"l2\"))\n",
    "])\n",
    "\n",
    "pipelineBestParams.fit(training_data['question'], training_data['label'])\n",
    "predictions = pipelineBestParams.predict(test_data['question'])\n",
    "\n",
    "report = sklearn.metrics.classification_report(test_data['label'], predictions)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
